#!/usr/bin/env python3
"""åˆ†æLLM Gatewayå®Œæ•´å¯¹è¯ï¼ˆè¯·æ±‚+å“åº”ï¼‰"""
import json
import sys
import re
from collections import defaultdict

def parse_sse_response(sse_text):
    """è§£æServer-Sent Eventsæ ¼å¼çš„å“åº”"""
    events = []
    full_text = ""
    usage = {}

    # æŒ‰ "event:" åˆ†å‰²SSEæµ
    parts = sse_text.split('event:')

    for part in parts:
        if not part.strip():
            continue

        lines = part.strip().split('\n', 1)
        if len(lines) < 2:
            continue

        event_type = lines[0].strip()
        data_part = lines[1]

        if not data_part.startswith('data:'):
            continue

        # æå–JSONï¼ˆå»æ‰"data:"å‰ç¼€ï¼Œæ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼‰
        json_str = data_part.replace('data:', '', 1).strip()

        # æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼ˆå¤„ç†åµŒå¥—å¤§æ‹¬å·ï¼‰
        brace_count = 0
        json_end = 0
        for i, char in enumerate(json_str):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    json_end = i + 1
                    break

        if json_end > 0:
            try:
                data = json.loads(json_str[:json_end])
                events.append({'type': event_type, 'data': data})

                # æå–æ–‡æœ¬å†…å®¹
                if event_type == 'content_block_delta':
                    text = data.get('delta', {}).get('text', '')
                    full_text += text

                # æå–usageä¿¡æ¯
                if event_type == 'message_delta':
                    usage = data.get('usage', {})
                elif event_type == 'message_start':
                    msg_usage = data.get('message', {}).get('usage', {})
                    if msg_usage:
                        usage.update(msg_usage)
            except:
                pass

    return full_text, usage, events

def analyze_conversations(log_file):
    """åˆ†æå®Œæ•´å¯¹è¯"""

    conversations = defaultdict(lambda: {'request': None, 'response': None, 'timestamp': None})

    print("=" * 100)
    print("ğŸ” LLM Gateway å¯¹è¯åˆ†æ - è¯·æ±‚ä¸å“åº”è¯¦æƒ…")
    print("=" * 100)

    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰æ•°æ®
    with open(log_file, 'r') as f:
        for line in f:
            try:
                log = json.loads(line.strip())

                if 'fields' not in log:
                    continue

                event_type = log['fields'].get('event_type')
                if not event_type:
                    continue

                request_id = log.get('span', {}).get('request_id')
                if not request_id:
                    continue

                if event_type == 'request_body':
                    try:
                        body = json.loads(log['fields']['body'])
                        conversations[request_id]['request'] = body
                        conversations[request_id]['model'] = log['span'].get('model')
                        conversations[request_id]['api_key'] = log['span'].get('api_key_name')
                        conversations[request_id]['timestamp'] = log.get('timestamp')
                    except:
                        pass

                elif event_type == 'response_body':
                    try:
                        body_text = log['fields']['body']
                        streaming = log['fields'].get('streaming', False)

                        conversations[request_id]['response_raw'] = body_text
                        conversations[request_id]['streaming'] = streaming

                        # è§£æå“åº”
                        if streaming:
                            # SSEæ ¼å¼
                            full_text, usage, events = parse_sse_response(body_text)
                            conversations[request_id]['response_text'] = full_text
                            conversations[request_id]['usage'] = usage
                        else:
                            # æ™®é€šJSONæ ¼å¼
                            resp_json = json.loads(body_text)
                            text = ""
                            if 'content' in resp_json and resp_json['content']:
                                for content in resp_json['content']:
                                    if isinstance(content, dict) and 'text' in content:
                                        text += content['text']
                            conversations[request_id]['response_text'] = text
                            conversations[request_id]['usage'] = resp_json.get('usage', {})
                    except Exception as e:
                        conversations[request_id]['parse_error'] = str(e)
                        pass

            except json.JSONDecodeError:
                continue

    # ç¬¬äºŒéï¼šè¾“å‡ºé…å¯¹çš„å¯¹è¯
    complete_conversations = {k: v for k, v in conversations.items()
                             if v['request'] is not None and 'response_text' in v}

    print(f"\næ‰¾åˆ° {len(complete_conversations)} ä¸ªå®Œæ•´å¯¹è¯ï¼ˆåŒ…å«è¯·æ±‚å’Œå“åº”ï¼‰\n")

    # è¾“å‡ºå‰5ä¸ªå¯¹è¯è¯¦æƒ…
    for idx, (request_id, conv) in enumerate(list(complete_conversations.items())[:5], 1):
        print(f"\n{'='*100}")
        print(f"å¯¹è¯ #{idx}")
        print(f"{'='*100}")
        print(f"Request ID: {request_id}")
        print(f"æ—¶é—´: {conv.get('timestamp', 'N/A')}")
        print(f"æ¨¡å‹: {conv.get('model', 'N/A')}")
        print(f"API Key: {conv.get('api_key', 'N/A')}")
        print(f"æµå¼å“åº”: {'æ˜¯' if conv.get('streaming') else 'å¦'}")

        req = conv['request']

        # 1. ç³»ç»Ÿæç¤ºè¯
        print(f"\n{'â”€'*100}")
        print("ğŸ“‹ ç³»ç»Ÿæç¤ºè¯ (System Prompt)")
        print(f"{'â”€'*100}")
        if 'system' in req and req['system']:
            for i, sys_msg in enumerate(req['system'], 1):
                if isinstance(sys_msg, dict) and 'text' in sys_msg:
                    text = sys_msg['text']
                    cache = sys_msg.get('cache_control', {}).get('type', '')
                    cache_mark = f" [ğŸ”µ Cached: {cache}]" if cache else ""

                    print(f"\nç³»ç»Ÿæç¤º #{i}{cache_mark}:")
                    if len(text) > 500:
                        print(f"{text[:500]}\n... (truncated, æ€»é•¿åº¦: {len(text)} å­—ç¬¦)")
                    else:
                        print(text)
        else:
            print("(æ— ç³»ç»Ÿæç¤º)")

        # 2. ç”¨æˆ·è¾“å…¥
        print(f"\n{'â”€'*100}")
        print("ğŸ’¬ ç”¨æˆ·è¾“å…¥ (User Messages)")
        print(f"{'â”€'*100}")
        if 'messages' in req and req['messages']:
            for msg_idx, msg in enumerate(req['messages'], 1):
                role = msg.get('role', 'unknown')

                if 'content' in msg:
                    if isinstance(msg['content'], str):
                        text = msg['content']
                    elif isinstance(msg['content'], list) and len(msg['content']) > 0:
                        content_item = msg['content'][0]
                        text = content_item.get('text', str(content_item))

                        # æ£€æŸ¥ç¼“å­˜
                        cache = content_item.get('cache_control', {}).get('type', '')
                        if cache:
                            text += f" [ğŸ”µ Cached: {cache}]"
                    else:
                        text = str(msg['content'])

                    print(f"\næ¶ˆæ¯ #{msg_idx} [{role}]:")
                    if len(text) > 600:
                        print(f"{text[:600]}\n... (truncated, æ€»é•¿åº¦: {len(text)} å­—ç¬¦)")
                    else:
                        print(text)

        # 3. è¯·æ±‚é…ç½®
        print(f"\n{'â”€'*100}")
        print("âš™ï¸  è¯·æ±‚é…ç½®")
        print(f"{'â”€'*100}")
        print(f"max_tokens: {req.get('max_tokens', 'N/A')}")
        print(f"temperature: {req.get('temperature', 'default')}")
        print(f"stream: {req.get('stream', False)}")

        if 'tools' in req and req['tools']:
            print(f"å·¥å…·æ•°é‡: {len(req['tools'])}")
            if len(req['tools']) <= 10:
                print("å·¥å…·åˆ—è¡¨:")
                for tool in req['tools'][:10]:
                    tool_name = tool.get('name', 'unknown')
                    if tool_name.startswith('mcp__'):
                        parts = tool_name.split('__')
                        if len(parts) >= 3:
                            tool_name = f"{parts[1]}/{parts[2]}"
                    desc = tool.get('description', '')
                    if len(desc) > 60:
                        desc = desc[:60] + "..."
                    print(f"  â€¢ {tool_name}: {desc}")

        if 'output_config' in req:
            output_fmt = req['output_config'].get('format', {}).get('type', 'text')
            print(f"è¾“å‡ºæ ¼å¼: {output_fmt}")
            if output_fmt == 'json_schema':
                schema = req['output_config']['format'].get('schema', {})
                if 'properties' in schema:
                    print(f"  Schemaå­—æ®µ: {', '.join(schema['properties'].keys())}")

        # 4. LLMå“åº”
        print(f"\n{'â”€'*100}")
        print("ğŸ¤– LLM å“åº” (Assistant Response)")
        print(f"{'â”€'*100}")
        response_text = conv.get('response_text', '')
        if response_text:
            if len(response_text) > 800:
                print(f"{response_text[:800]}\n... (truncated, æ€»é•¿åº¦: {len(response_text)} å­—ç¬¦)")
            else:
                print(response_text)
        else:
            print("(æ— å“åº”å†…å®¹æˆ–è§£æå¤±è´¥)")

        # 5. Tokenä½¿ç”¨æƒ…å†µ
        if 'usage' in conv and conv['usage']:
            usage = conv['usage']
            print(f"\n{'â”€'*100}")
            print("ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡")
            print(f"{'â”€'*100}")
            print(f"è¾“å…¥ tokens: {usage.get('input_tokens', 0)}")
            print(f"è¾“å‡º tokens: {usage.get('output_tokens', 0)}")

            if usage.get('cache_creation_input_tokens'):
                print(f"ç¼“å­˜åˆ›å»º tokens: {usage.get('cache_creation_input_tokens', 0)} (æˆæœ¬ +25%)")
            if usage.get('cache_read_input_tokens'):
                print(f"ç¼“å­˜è¯»å– tokens: {usage.get('cache_read_input_tokens', 0)} (æˆæœ¬ -90%)")

            total = usage.get('input_tokens', 0) + usage.get('output_tokens', 0)
            print(f"æ€»è®¡: {total} tokens")

    # æ€»ç»“ç»Ÿè®¡
    print(f"\n{'='*100}")
    print("ğŸ“ˆ å¯¹è¯ç»Ÿè®¡æ‘˜è¦")
    print(f"{'='*100}")

    total_input = sum(conv.get('usage', {}).get('input_tokens', 0) for conv in complete_conversations.values())
    total_output = sum(conv.get('usage', {}).get('output_tokens', 0) for conv in complete_conversations.values())
    total_cache_read = sum(conv.get('usage', {}).get('cache_read_input_tokens', 0) for conv in complete_conversations.values())
    total_cache_create = sum(conv.get('usage', {}).get('cache_creation_input_tokens', 0) for conv in complete_conversations.values())

    print(f"æ€»å¯¹è¯æ•°: {len(complete_conversations)}")
    print(f"æ€»è¾“å…¥ tokens: {total_input:,}")
    print(f"æ€»è¾“å‡º tokens: {total_output:,}")
    print(f"ç¼“å­˜è¯»å– tokens: {total_cache_read:,}")
    print(f"ç¼“å­˜åˆ›å»º tokens: {total_cache_create:,}")
    print(f"æ€»è®¡: {total_input + total_output:,} tokens")

    # ç¼“å­˜æ•ˆç‡
    if total_cache_read > 0:
        cache_ratio = (total_cache_read / (total_input or 1)) * 100
        print(f"\nç¼“å­˜å‘½ä¸­ç‡: {cache_ratio:.1f}%")
        print(f"é€šè¿‡ç¼“å­˜èŠ‚çœçš„æˆæœ¬çº¦: {total_cache_read * 0.9:,.0f} tokens ç­‰æ•ˆæˆæœ¬")

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("Usage: python analyze_conversations.py <log_file>")
        sys.exit(1)

    analyze_conversations(sys.argv[1])
