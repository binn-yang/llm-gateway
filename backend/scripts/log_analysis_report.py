#!/usr/bin/env python3
"""åˆ†æLLM Gatewayæ—¥å¿—æ–‡ä»¶"""
import json
import sys
from collections import defaultdict, Counter
from datetime import datetime

def analyze_detailed_logs(log_file):
    """è¯¦ç»†åˆ†ææ—¥å¿—æ–‡ä»¶"""

    request_bodies = []
    conversations = defaultdict(dict)
    errors = []
    stats = {
        'total_requests': 0,
        'models': Counter(),
        'api_keys': Counter(),
        'errors': Counter(),
    }

    print("=" * 100)
    print("LLM Gateway æ—¥å¿—åˆ†ææŠ¥å‘Š")
    print("=" * 100)

    with open(log_file, 'r') as f:
        for line in f:
            try:
                log = json.loads(line.strip())

                # ç»Ÿè®¡é”™è¯¯
                if log.get('level') == 'ERROR':
                    error_msg = log.get('fields', {}).get('message', '')
                    errors.append({
                        'time': log.get('timestamp'),
                        'message': error_msg,
                        'target': log.get('target')
                    })
                    stats['errors'][error_msg] += 1

                # å¤„ç†è¯·æ±‚bodyäº‹ä»¶
                if log.get('fields', {}).get('event_type') == 'request_body':
                    stats['total_requests'] += 1
                    request_id = log.get('span', {}).get('request_id')

                    try:
                        body = json.loads(log['fields']['body'])
                        model = body.get('model', 'unknown')
                        stats['models'][model] += 1

                        api_key = log.get('span', {}).get('api_key_name', 'unknown')
                        stats['api_keys'][api_key] += 1

                        conversations[request_id] = {
                            'model': model,
                            'api_key': api_key,
                            'request': body,
                            'timestamp': log.get('timestamp')
                        }

                        request_bodies.append({
                            'request_id': request_id,
                            'model': model,
                            'body': body
                        })
                    except:
                        pass

            except json.JSONDecodeError:
                continue

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ")
    print("-" * 100)
    print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"é”™è¯¯æ•°: {sum(stats['errors'].values())}")
    print(f"\nä½¿ç”¨çš„æ¨¡å‹:")
    for model, count in stats['models'].most_common():
        print(f"  - {model}: {count} æ¬¡")
    print(f"\nAPI Keys:")
    for key, count in stats['api_keys'].most_common():
        print(f"  - {key}: {count} æ¬¡")

    # è¾“å‡ºé”™è¯¯ä¿¡æ¯
    if errors:
        print(f"\nâš ï¸  é”™è¯¯åˆ—è¡¨ (æœ€è¿‘10ä¸ª)")
        print("-" * 100)
        for error in errors[-10:]:
            print(f"æ—¶é—´: {error['time']}")
            print(f"æ¶ˆæ¯: {error['message']}")
            print(f"æ¥æº: {error['target']}")
            print()

    # è¾“å‡ºå‰5ä¸ªå¯¹è¯è¯¦æƒ…
    print(f"\nğŸ’¬ å¯¹è¯è¯¦æƒ… (å‰5ä¸ª)")
    print("=" * 100)

    for idx, (request_id, data) in enumerate(list(conversations.items())[:5], 1):
        print(f"\nã€å¯¹è¯ #{idx}ã€‘")
        print(f"Request ID: {request_id}")
        print(f"æ—¶é—´: {data.get('timestamp', 'N/A')}")
        print(f"æ¨¡å‹: {data.get('model')}")
        print(f"API Key: {data.get('api_key')}")
        print("-" * 100)

        req = data['request']

        # ç³»ç»Ÿæç¤º
        if 'system' in req and req['system']:
            print(f"\nğŸ”§ ç³»ç»Ÿæç¤ºè¯:")
            for i, sys_msg in enumerate(req['system'][:3], 1):
                if isinstance(sys_msg, dict) and 'text' in sys_msg:
                    text = sys_msg['text']
                    # æ£€æŸ¥æ˜¯å¦æœ‰cache_control
                    cache = sys_msg.get('cache_control', {}).get('type', '')
                    cache_mark = " [cached]" if cache else ""

                    if len(text) > 150:
                        text = text[:150] + "..."
                    print(f"  {i}. {text}{cache_mark}")

        # ç”¨æˆ·æ¶ˆæ¯
        if 'messages' in req and req['messages']:
            print(f"\nğŸ‘¤ ç”¨æˆ·è¾“å…¥:")
            for msg in req['messages'][:2]:
                role = msg.get('role', 'unknown')

                if 'content' in msg:
                    if isinstance(msg['content'], str):
                        text = msg['content']
                    elif isinstance(msg['content'], list) and len(msg['content']) > 0:
                        content_item = msg['content'][0]
                        text = content_item.get('text', str(content_item)[:100])

                        # æ£€æŸ¥æ˜¯å¦æœ‰cache_control
                        cache = content_item.get('cache_control', {}).get('type', '')
                        if cache:
                            text += f" [cached: {cache}]"
                    else:
                        text = str(msg['content'])[:100]

                    if len(text) > 300:
                        text = text[:300] + "..."

                    print(f"  [{role}] {text}")

        # é…ç½®å‚æ•°
        print(f"\nâš™ï¸  è¯·æ±‚å‚æ•°:")
        print(f"  - max_tokens: {req.get('max_tokens', 'N/A')}")
        print(f"  - stream: {req.get('stream', False)}")
        print(f"  - temperature: {req.get('temperature', 'default')}")

        # å·¥å…·æ•°é‡
        if 'tools' in req and req['tools']:
            print(f"  - å·¥å…·æ•°é‡: {len(req['tools'])}")
            if len(req['tools']) <= 5:
                print(f"  - å·¥å…·åˆ—è¡¨:")
                for tool in req['tools'][:5]:
                    tool_name = tool.get('name', 'unknown')
                    # ç®€åŒ–MCPå·¥å…·åç§°
                    if tool_name.startswith('mcp__'):
                        tool_name = tool_name.split('__')[-1]
                    print(f"      * {tool_name}")

        # è¾“å‡ºé…ç½®
        if 'output_config' in req:
            output_cfg = req['output_config']
            print(f"  - è¾“å‡ºæ ¼å¼: {output_cfg.get('format', {}).get('type', 'text')}")

        print()

    # åˆ†æå®¢æˆ·ç«¯äº¤äº’æ¨¡å¼
    print("\n" + "=" * 100)
    print("ğŸ“ å®¢æˆ·ç«¯äº¤äº’æ¨¡å¼åˆ†æ")
    print("=" * 100)

    # ç»Ÿè®¡å„ç§äº¤äº’ç±»å‹
    interaction_types = Counter()
    has_tools = 0
    has_system_prompt = 0
    has_cache = 0
    streaming_count = 0

    for conv in conversations.values():
        req = conv['request']

        if req.get('stream'):
            streaming_count += 1

        if req.get('tools'):
            has_tools += 1
            interaction_types['å·¥å…·è°ƒç”¨'] += 1

        if req.get('system'):
            has_system_prompt += 1

        # æ£€æŸ¥ç¼“å­˜ä½¿ç”¨
        if req.get('system'):
            for sys_msg in req['system']:
                if isinstance(sys_msg, dict) and sys_msg.get('cache_control'):
                    has_cache += 1
                    interaction_types['ä½¿ç”¨ç¼“å­˜'] += 1
                    break

        # æ£€æŸ¥è¾“å‡ºæ ¼å¼
        if 'output_config' in req:
            fmt = req['output_config'].get('format', {}).get('type')
            if fmt == 'json_schema':
                interaction_types['ç»“æ„åŒ–è¾“å‡º(JSON Schema)'] += 1

    print(f"\näº¤äº’ç‰¹å¾:")
    print(f"  - ä½¿ç”¨æµå¼å“åº”: {streaming_count}/{len(conversations)} ({streaming_count/len(conversations)*100:.1f}%)")
    print(f"  - åŒ…å«å·¥å…·è°ƒç”¨: {has_tools}/{len(conversations)} ({has_tools/len(conversations)*100:.1f}%)")
    print(f"  - åŒ…å«ç³»ç»Ÿæç¤º: {has_system_prompt}/{len(conversations)} ({has_system_prompt/len(conversations)*100:.1f}%)")
    print(f"  - ä½¿ç”¨promptç¼“å­˜: {has_cache}/{len(conversations)} ({has_cache/len(conversations)*100:.1f}%)")

    print(f"\näº¤äº’ç±»å‹åˆ†å¸ƒ:")
    for itype, count in interaction_types.most_common():
        print(f"  - {itype}: {count} æ¬¡")

    print("\n" + "=" * 100)

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("Usage: python log_analysis_report.py <log_file>")
        sys.exit(1)

    analyze_detailed_logs(sys.argv[1])
